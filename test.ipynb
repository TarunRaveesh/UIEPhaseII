{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1c903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "import pytorch_ssim\n",
    "import  time \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn.modules.loss import _Loss \n",
    "from net.Ushape_Trans import *\n",
    "#from dataset import prepare_data, Dataset\n",
    "from net.utils import *\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utility import plots as plots, ptcolor as ptcolor, ptutils as ptutils, data as data\n",
    "from loss.LAB import *\n",
    "from loss.LCH import *\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f986a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fccf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(img):\n",
    "    output=[]\n",
    "    output.append(F.interpolate(img, scale_factor=0.125))\n",
    "    output.append(F.interpolate(img, scale_factor=0.25))\n",
    "    output.append(F.interpolate(img, scale_factor=0.5))\n",
    "    output.append(img)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733afcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tarun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\\torch\\csrc\\tensor\\python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "dtype = 'float32'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52453181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize generator \n",
    "generator = Generator().cuda()\n",
    "generator.load_state_dict(torch.load(\"./saved_models/G/generator_795.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8314e271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (linear_encoding): Linear(in_features=384, out_features=512, bias=True)\n",
       "  (position_encoding): LearnedPositionalEncoding()\n",
       "  (pe_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (transformer): TransformerModel(\n",
       "    (net): IntermediateSequential(\n",
       "      (0): Residual(\n",
       "        (fn): PreNormDrop(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (fn): SelfAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (fn): PreNorm(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Residual(\n",
       "        (fn): PreNormDrop(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (fn): SelfAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Residual(\n",
       "        (fn): PreNorm(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Residual(\n",
       "        (fn): PreNormDrop(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (fn): SelfAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Residual(\n",
       "        (fn): PreNorm(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): Residual(\n",
       "        (fn): PreNormDrop(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (fn): SelfAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Residual(\n",
       "        (fn): PreNorm(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_head_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (Conv_x): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (rgb_to_feature): ModuleList(\n",
       "    (0): from_rgb(\n",
       "      (conv_1): _equalized_conv2d(32, 3, 1, 1)\n",
       "      (pixNorm): PixelwiseNorm()\n",
       "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): from_rgb(\n",
       "      (conv_1): _equalized_conv2d(64, 3, 1, 1)\n",
       "      (pixNorm): PixelwiseNorm()\n",
       "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (2): from_rgb(\n",
       "      (conv_1): _equalized_conv2d(128, 3, 1, 1)\n",
       "      (pixNorm): PixelwiseNorm()\n",
       "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (feature_to_rgb): ModuleList(\n",
       "    (0): to_rgb(\n",
       "      (conv_1): _equalized_conv2d(3, 32, 1, 1)\n",
       "    )\n",
       "    (1): to_rgb(\n",
       "      (conv_1): _equalized_conv2d(3, 64, 1, 1)\n",
       "    )\n",
       "    (2): to_rgb(\n",
       "      (conv_1): _equalized_conv2d(3, 128, 1, 1)\n",
       "    )\n",
       "    (3): to_rgb(\n",
       "      (conv_1): _equalized_conv2d(3, 256, 1, 1)\n",
       "    )\n",
       "  )\n",
       "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv1): conv_block(\n",
       "    (conv_1): _equalized_conv2d(16, 3, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(16, 16, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(16, 16, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Conv1_1): conv_block(\n",
       "    (conv_1): _equalized_conv2d(32, 16, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Conv2): conv_block(\n",
       "    (conv_1): _equalized_conv2d(32, 32, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Conv2_1): conv_block(\n",
       "    (conv_1): _equalized_conv2d(64, 32, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Conv3): conv_block(\n",
       "    (conv_1): _equalized_conv2d(64, 64, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Conv3_1): conv_block(\n",
       "    (conv_1): _equalized_conv2d(128, 64, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Conv4): conv_block(\n",
       "    (conv_1): _equalized_conv2d(128, 128, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Conv4_1): conv_block(\n",
       "    (conv_1): _equalized_conv2d(256, 128, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Conv5): conv_block(\n",
       "    (conv_1): _equalized_conv2d(256, 512, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (mtc): ChannelTransformer(\n",
       "    (embeddings_1): Channel_Embeddings(\n",
       "      (patch_embeddings): Conv2d(32, 32, kernel_size=(32, 32), stride=(32, 32))\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_2): Channel_Embeddings(\n",
       "      (patch_embeddings): Conv2d(64, 64, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_3): Channel_Embeddings(\n",
       "      (patch_embeddings): Conv2d(128, 128, kernel_size=(8, 8), stride=(8, 8))\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_4): Channel_Embeddings(\n",
       "      (patch_embeddings): Conv2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x Block_ViT(\n",
       "          (attn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn_norm): LayerNorm((480,), eps=1e-06, elementwise_affine=True)\n",
       "          (channel_attn): Attention_org(\n",
       "            (query1): ModuleList(\n",
       "              (0-3): 4 x Linear(in_features=32, out_features=32, bias=False)\n",
       "            )\n",
       "            (query2): ModuleList(\n",
       "              (0-3): 4 x Linear(in_features=64, out_features=64, bias=False)\n",
       "            )\n",
       "            (query3): ModuleList(\n",
       "              (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "            )\n",
       "            (query4): ModuleList(\n",
       "              (0-3): 4 x Linear(in_features=256, out_features=256, bias=False)\n",
       "            )\n",
       "            (key): ModuleList(\n",
       "              (0-3): 4 x Linear(in_features=480, out_features=480, bias=False)\n",
       "            )\n",
       "            (value): ModuleList(\n",
       "              (0-3): 4 x Linear(in_features=480, out_features=480, bias=False)\n",
       "            )\n",
       "            (psi): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (softmax): Softmax(dim=3)\n",
       "            (out1): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (out2): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (out3): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (out4): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ffn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "          (ffn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (ffn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (ffn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (ffn1): Mlp(\n",
       "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (act_fn): GELU(approximate='none')\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ffn2): Mlp(\n",
       "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (act_fn): GELU(approximate='none')\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ffn3): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (act_fn): GELU(approximate='none')\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ffn4): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (act_fn): GELU(approximate='none')\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (encoder_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (encoder_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      (encoder_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (encoder_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (reconstruct_1): Reconstruct(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (reconstruct_2): Reconstruct(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (reconstruct_3): Reconstruct(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (reconstruct_4): Reconstruct(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up5): up_conv(\n",
       "    (conv_1): _equalized_conv2d(256, 256, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (coatt5): CCA(\n",
       "    (mlp_x): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (mlp_g): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv5): conv_block(\n",
       "    (conv_1): _equalized_conv2d(256, 512, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Up_conv5_1): conv_block(\n",
       "    (conv_1): _equalized_conv2d(256, 256, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Up4): up_conv(\n",
       "    (conv_1): _equalized_conv2d(128, 256, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (coatt4): CCA(\n",
       "    (mlp_x): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (mlp_g): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv4): conv_block(\n",
       "    (conv_1): _equalized_conv2d(128, 256, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Up_conv4_1): conv_block(\n",
       "    (conv_1): _equalized_conv2d(128, 128, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Up3): up_conv(\n",
       "    (conv_1): _equalized_conv2d(64, 128, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (coatt3): CCA(\n",
       "    (mlp_x): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (mlp_g): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv3): conv_block(\n",
       "    (conv_1): _equalized_conv2d(64, 128, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Up_conv3_1): conv_block(\n",
       "    (conv_1): _equalized_conv2d(64, 64, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Up2): up_conv(\n",
       "    (conv_1): _equalized_conv2d(32, 64, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (coatt2): CCA(\n",
       "    (mlp_x): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (mlp_g): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv2): conv_block(\n",
       "    (conv_1): _equalized_conv2d(32, 64, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Up_conv2_1): conv_block(\n",
       "    (conv_1): _equalized_conv2d(32, 32, 1, 1)\n",
       "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
       "    (pixNorm): PixelwiseNorm()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Conv): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a238c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./test/input/'\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "i=1\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
    "    imgx = np.array(imgx).astype(dtype)\n",
    "\n",
    "    imgx= torch.from_numpy(imgx)\n",
    "    imgx=imgx.permute(2,0,1).unsqueeze(0)\n",
    "    imgx=imgx/255.0\n",
    "    #plt.imshow(imgx[0,:,:,:])\n",
    "    #plt.show()\n",
    "    imgx = Variable(imgx).cuda()\n",
    "    #print(imgx.shape)\n",
    "    output=generator(imgx)\n",
    "    out=output[3].data\n",
    "    save_image(out, \"./test/output/\"+item, nrow=5, normalize=True)\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f216c",
   "metadata": {},
   "source": [
    "### SSIM & PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3cc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def getSSIM(X, Y):\n",
    "    \"\"\"\n",
    "       Computes the mean structural similarity between two images.\n",
    "    \"\"\"\n",
    "    assert (X.shape == Y.shape), \"Image-patche provided have different dimensions\"\n",
    "    nch = 1 if X.ndim==2 else X.shape[-1]\n",
    "    mssim = []\n",
    "    for ch in range(nch):\n",
    "        Xc, Yc = X[...,ch].astype(np.float64), Y[...,ch].astype(np.float64)\n",
    "        mssim.append(compute_ssim(Xc, Yc))\n",
    "    return np.mean(mssim)\n",
    "\n",
    "\n",
    "def compute_ssim(X, Y):\n",
    "    \"\"\"\n",
    "       Compute the structural similarity per single channel (given two images)\n",
    "    \"\"\"\n",
    "    # variables are initialized as suggested in the paper\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    sigma = 1.5\n",
    "    win_size = 5\n",
    "\n",
    "    # means\n",
    "    ux = gaussian_filter(X, sigma)\n",
    "    uy = gaussian_filter(Y, sigma)\n",
    "\n",
    "    # variances and covariances\n",
    "    uxx = gaussian_filter(X * X, sigma)\n",
    "    uyy = gaussian_filter(Y * Y, sigma)\n",
    "    uxy = gaussian_filter(X * Y, sigma)\n",
    "\n",
    "    # normalize by unbiased estimate of std dev\n",
    "    N = win_size ** X.ndim\n",
    "    unbiased_norm = N / (N - 1)  # eq. 4 of the paper\n",
    "    vx  = (uxx - ux * ux) * unbiased_norm\n",
    "    vy  = (uyy - uy * uy) * unbiased_norm\n",
    "    vxy = (uxy - ux * uy) * unbiased_norm\n",
    "\n",
    "    R = 255\n",
    "    C1 = (K1 * R) ** 2\n",
    "    C2 = (K2 * R) ** 2\n",
    "    # compute SSIM (eq. 13 of the paper)\n",
    "    sim = (2 * ux * uy + C1) * (2 * vxy + C2)\n",
    "    D = (ux ** 2 + uy ** 2 + C1) * (vx + vy + C2)\n",
    "    SSIM = sim/D\n",
    "    mssim = SSIM.mean()\n",
    "\n",
    "    return mssim\n",
    "\n",
    "\n",
    "\n",
    "def getPSNR(X, Y):\n",
    "    #assume RGB image\n",
    "    target_data = np.array(X, dtype=np.float64)\n",
    "    ref_data = np.array(Y, dtype=np.float64)\n",
    "    diff = ref_data - target_data\n",
    "    diff = diff.flatten('C')\n",
    "    rmse = math.sqrt(np.mean(diff ** 2.) )\n",
    "    if rmse == 0: return 100\n",
    "    else: return 20*math.log10(255.0/rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fdd6a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SSIM: 0.7997773020970781\n",
      "Average PSNR: 22.01350578455024\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from os.path import join, basename\n",
    "\n",
    "def calculate_metrics(gtr_dir, gen_dir, im_res=(256, 256)):\n",
    "    gtr_paths = sorted(glob(join(gtr_dir, \"*.*\")))\n",
    "    gen_paths = sorted(glob(join(gen_dir, \"*.*\")))\n",
    "    ssims, psnrs = [], []\n",
    "\n",
    "    for gtr_path, gen_path in zip(gtr_paths, gen_paths):\n",
    "        gtr_f = basename(gtr_path).split('.')[0]\n",
    "        gen_f = basename(gen_path).split('.')[0]\n",
    "\n",
    "        if (gtr_f == gen_f):\n",
    "            r_im = Image.open(gtr_path).resize(im_res)\n",
    "            g_im = Image.open(gen_path).resize(im_res)\n",
    "\n",
    "            # Calculate SSIM on RGB channels\n",
    "            ssim = getSSIM(np.array(r_im), np.array(g_im))\n",
    "            ssims.append(ssim)\n",
    "\n",
    "            # Calculate PSNR on L channel (SOTA norm)\n",
    "            r_im = r_im.convert(\"L\")\n",
    "            g_im = g_im.convert(\"L\")\n",
    "            psnr = getPSNR(np.array(r_im), np.array(g_im))\n",
    "            psnrs.append(psnr)\n",
    "\n",
    "    return np.array(ssims), np.array(psnrs)\n",
    "\n",
    "# Define directories\n",
    "gtr_directory = 'test\\input'  # Ground truth directory\n",
    "gen_directory = 'test\\output'   # Generated images directory\n",
    "\n",
    "# Calculate SSIM and PSNR\n",
    "ssim_scores, psnr_scores = calculate_metrics(gtr_directory, gen_directory)\n",
    "\n",
    "# Calculate average SSIM and PSNR\n",
    "avg_ssim = np.mean(ssim_scores)\n",
    "avg_psnr = np.mean(psnr_scores)\n",
    "\n",
    "print(f\"Average SSIM: {avg_ssim}\")\n",
    "print(f\"Average PSNR: {avg_psnr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c5bd4",
   "metadata": {},
   "source": [
    "### UIQM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34084087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def mu_a(x, alpha_L=0.1, alpha_R=0.1):\n",
    "    \"\"\"\n",
    "      Calculates the asymetric alpha-trimmed mean\n",
    "    \"\"\"\n",
    "    # sort pixels by intensity - for clipping\n",
    "    x = sorted(x)\n",
    "    # get number of pixels\n",
    "    K = len(x)\n",
    "    # calculate T alpha L and T alpha R\n",
    "    T_a_L = math.ceil(alpha_L*K)\n",
    "    T_a_R = math.floor(alpha_R*K)\n",
    "    # calculate mu_alpha weight\n",
    "    weight = (1/(K-T_a_L-T_a_R))\n",
    "    # loop through flattened image starting at T_a_L+1 and ending at K-T_a_R\n",
    "    s   = int(T_a_L+1)\n",
    "    e   = int(K-T_a_R)\n",
    "    val = sum(x[s:e])\n",
    "    val = weight*val\n",
    "    return val\n",
    "\n",
    "def s_a(x, mu):\n",
    "    val = 0\n",
    "    for pixel in x:\n",
    "        val += math.pow((pixel-mu), 2)\n",
    "    return val/len(x)\n",
    "\n",
    "def _uicm(x):\n",
    "    R = x[:,:,0].flatten()\n",
    "    G = x[:,:,1].flatten()\n",
    "    B = x[:,:,2].flatten()\n",
    "    RG = R-G\n",
    "    YB = ((R+G)/2)-B\n",
    "    mu_a_RG = mu_a(RG)\n",
    "    mu_a_YB = mu_a(YB)\n",
    "    s_a_RG = s_a(RG, mu_a_RG)\n",
    "    s_a_YB = s_a(YB, mu_a_YB)\n",
    "    l = math.sqrt( (math.pow(mu_a_RG,2)+math.pow(mu_a_YB,2)) )\n",
    "    r = math.sqrt(s_a_RG+s_a_YB)\n",
    "    return (-0.0268*l)+(0.1586*r)\n",
    "\n",
    "def sobel(x):\n",
    "    dx = ndimage.sobel(x,0)\n",
    "    dy = ndimage.sobel(x,1)\n",
    "    mag = np.hypot(dx, dy)\n",
    "    mag *= 255.0 / np.max(mag)\n",
    "    return mag\n",
    "\n",
    "def eme(x, window_size):\n",
    "    \"\"\"\n",
    "      Enhancement measure estimation\n",
    "      x.shape[0] = height\n",
    "      x.shape[1] = width\n",
    "    \"\"\"\n",
    "    # if 4 blocks, then 2x2...etc.\n",
    "    k1 = int(x.shape[1]/window_size)\n",
    "    k2 = int(x.shape[0]/window_size)\n",
    "    # weight\n",
    "    w = 2./(k1*k2)\n",
    "    blocksize_x = window_size\n",
    "    blocksize_y = window_size\n",
    "    # make sure image is divisible by window_size - doesn't matter if we cut out some pixels\n",
    "    x = x[:blocksize_y*k2, :blocksize_x*k1]\n",
    "    val = 0\n",
    "    for l in range(k1):\n",
    "        for k in range(k2):\n",
    "            block = x[k*window_size:window_size*(k+1), l*window_size:window_size*(l+1)]\n",
    "            max_ = np.max(block)\n",
    "            min_ = np.min(block)\n",
    "            # bound checks, can't do log(0)\n",
    "            if min_ == 0.0: val += 0\n",
    "            elif max_ == 0.0: val += 0\n",
    "            else: val += math.log(max_/min_)\n",
    "    return w*val\n",
    "\n",
    "def _uism(x):\n",
    "    \"\"\"\n",
    "      Underwater Image Sharpness Measure\n",
    "    \"\"\"\n",
    "    # get image channels\n",
    "    R = x[:,:,0]\n",
    "    G = x[:,:,1]\n",
    "    B = x[:,:,2]\n",
    "    # first apply Sobel edge detector to each RGB component\n",
    "    Rs = sobel(R)\n",
    "    Gs = sobel(G)\n",
    "    Bs = sobel(B)\n",
    "    # multiply the edges detected for each channel by the channel itself\n",
    "    R_edge_map = np.multiply(Rs, R)\n",
    "    G_edge_map = np.multiply(Gs, G)\n",
    "    B_edge_map = np.multiply(Bs, B)\n",
    "    # get eme for each channel\n",
    "    r_eme = eme(R_edge_map, 10)\n",
    "    g_eme = eme(G_edge_map, 10)\n",
    "    b_eme = eme(B_edge_map, 10)\n",
    "    # coefficients\n",
    "    lambda_r = 0.299\n",
    "    lambda_g = 0.587\n",
    "    lambda_b = 0.144\n",
    "    return (lambda_r*r_eme) + (lambda_g*g_eme) + (lambda_b*b_eme)\n",
    "\n",
    "def plip_g(x,mu=1026.0):\n",
    "    return mu-x\n",
    "\n",
    "def plip_theta(g1, g2, k):\n",
    "    g1 = plip_g(g1)\n",
    "    g2 = plip_g(g2)\n",
    "    return k*((g1-g2)/(k-g2))\n",
    "\n",
    "def plip_cross(g1, g2, gamma):\n",
    "    g1 = plip_g(g1)\n",
    "    g2 = plip_g(g2)\n",
    "    return g1+g2-((g1*g2)/(gamma))\n",
    "\n",
    "def plip_diag(c, g, gamma):\n",
    "    g = plip_g(g)\n",
    "    return gamma - (gamma * math.pow((1 - (g/gamma) ), c) )\n",
    "\n",
    "def plip_multiplication(g1, g2):\n",
    "    return plip_phiInverse(plip_phi(g1) * plip_phi(g2))\n",
    "    #return plip_phiInverse(plip_phi(plip_g(g1)) * plip_phi(plip_g(g2)))\n",
    "\n",
    "def plip_phiInverse(g):\n",
    "    plip_lambda = 1026.0\n",
    "    plip_beta   = 1.0\n",
    "    return plip_lambda * (1 - math.pow(math.exp(-g / plip_lambda), 1 / plip_beta));\n",
    "\n",
    "def plip_phi(g):\n",
    "    plip_lambda = 1026.0\n",
    "    plip_beta   = 1.0\n",
    "    return -plip_lambda * math.pow(math.log(1 - g / plip_lambda), plip_beta)\n",
    "\n",
    "def _uiconm(x, window_size):\n",
    "    \"\"\"\n",
    "      Underwater image contrast measure\n",
    "      https://github.com/tkrahn108/UIQM/blob/master/src/uiconm.cpp\n",
    "      https://ieeexplore.ieee.org/abstract/document/5609219\n",
    "    \"\"\"\n",
    "    plip_lambda = 1026.0\n",
    "    plip_gamma  = 1026.0\n",
    "    plip_beta   = 1.0\n",
    "    plip_mu     = 1026.0\n",
    "    plip_k      = 1026.0\n",
    "    # if 4 blocks, then 2x2...etc.\n",
    "    k1 = int(x.shape[1]/window_size)\n",
    "    k2 = int(x.shape[0]/window_size)\n",
    "    # weight\n",
    "    w = -1./(k1*k2)\n",
    "    blocksize_x = window_size\n",
    "    blocksize_y = window_size\n",
    "    # make sure image is divisible by window_size - doesn't matter if we cut out some pixels\n",
    "    x = x[:blocksize_y*k2, :blocksize_x*k1]\n",
    "    # entropy scale - higher helps with randomness\n",
    "    alpha = 1\n",
    "    val = 0\n",
    "    for l in range(k1):\n",
    "        for k in range(k2):\n",
    "            block = x[k*window_size:window_size*(k+1), l*window_size:window_size*(l+1), :]\n",
    "            max_ = np.max(block)\n",
    "            min_ = np.min(block)\n",
    "            top = max_-min_\n",
    "            bot = max_+min_\n",
    "            if math.isnan(top) or math.isnan(bot) or bot == 0.0 or top == 0.0: val += 0.0\n",
    "            else: val += alpha*math.pow((top/bot),alpha) * math.log(top/bot)\n",
    "            #try: val += plip_multiplication((top/bot),math.log(top/bot))\n",
    "    return w*val\n",
    "\n",
    "def getUIQM(x):\n",
    "    \"\"\"\n",
    "      Function to return UIQM to be called from other programs\n",
    "      x: image\n",
    "    \"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "    c1 = 0.0282; c2 = 0.2953; c3 = 3.5753\n",
    "    uicm   = _uicm(x)\n",
    "    uism   = _uism(x)\n",
    "    uiconm = _uiconm(x, 10)\n",
    "    uiqm = (c1*uicm) + (c2*uism) + (c3*uiconm)\n",
    "    return uiqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1db2ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average UIQM: 2.9194615631938543\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from os.path import join, basename\n",
    "from ntpath import basename  # You may not need this if you've already imported it\n",
    "\n",
    "def calculate_UIQMs(dir_name, im_res=(256, 256)):\n",
    "    paths = sorted(glob(join(dir_name, \"*.*\")))\n",
    "    uqims = []\n",
    "\n",
    "    for img_path in paths:\n",
    "        im = Image.open(img_path).resize(im_res)\n",
    "        uiqm = getUIQM(np.array(im))\n",
    "        uqims.append(uiqm)\n",
    "\n",
    "    return np.array(uqims)\n",
    "\n",
    "# Define the directory\n",
    "image_directory = 'test/output'  # The directory containing the images\n",
    "\n",
    "# Calculate UIQMs\n",
    "uiqm_scores = calculate_UIQMs(image_directory)\n",
    "\n",
    "# Calculate the average UIQM score\n",
    "avg_uiqm = np.mean(uiqm_scores)\n",
    "\n",
    "print(f\"Average UIQM: {avg_uiqm}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
